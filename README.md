# Citation DOI Validator

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![DOI](https://img.shields.io/badge/DOI-pending-blue.svg)]()

**Academic Citation Verification Tool** - Automatically verify citations in BibTeX files to detect fabricated references, invalid DOIs, and author mismatches.

üîç **Detects**: Fabricated citations, invalid DOIs, author mismatches, title errors, year discrepancies
üìä **Verifies**: DOIs via CrossRef + doi.org, authors via fuzzy matching, metadata via Semantic Scholar
üîß **Fixes**: Auto-generates corrected BibTeX entries for common errors
üìù **Reports**: Markdown, JSON, or plain text with comprehensive analysis

---

## ‚ú® Features

- ‚úÖ **Multi-API Verification**: CrossRef, doi.org Handle System, Semantic Scholar
- ‚úÖ **Intelligent DOI Validation**: Verifies DOI existence and resolves to correct metadata
- ‚úÖ **Author Matching**: Fuzzy string matching detects author name variations and fabrications
- ‚úÖ **Comprehensive Checks**: Title, authors, year, venue, publication type
- ‚úÖ **Auto-Fix Generation**: Suggests corrected BibTeX entries with copy-paste fixes
- ‚úÖ **Multiple Output Formats**: Markdown (GitHub-friendly), JSON (machine-readable), plain text
- ‚úÖ **Rate Limiting**: Respects API quotas automatically
- ‚úÖ **Batch Processing**: Verify 1 citation or 1,000+ citations efficiently
- ‚úÖ **Detailed Reports**: Executive summary, status badges, fix suggestions, fraud/error rates

---

## üöÄ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/lnm8910/citation-doi-validator.git
cd citation-doi-validator

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

```bash
# Verify first 10 citations in references.bib
python citation_validator.py --bib references.bib --start 1 --end 10

# Generate markdown report
python citation_validator.py --start 1 --end 50 --output report.md

# Verify specific citation by key
python citation_validator.py --key "smith2023paper" --output single.md --verbose

# Save as JSON
python citation_validator.py --start 1 --end 100 --output results.json --format json
```

---

## üìñ Detailed Usage

### Command-Line Options

```
usage: citation_validator.py [-h] [--bib BIB] [--start START] [--end END]
                             [--key KEY] [--output OUTPUT]
                             [--format {text,json,markdown,md}]
                             [--verbose] [--version]

options:
  --bib BIB              Path to BibTeX file (default: references.bib)
  --start START          Start index (1-based, inclusive)
  --end END              End index (1-based, inclusive)
  --key KEY              Verify specific citation by BibTeX key
  --output, -o OUTPUT    Output file path (default: stdout)
  --format, -f FORMAT    Output format: text, json, markdown (default: markdown)
  --verbose, -v          Enable verbose logging
  --version              Show version and exit
```

### Examples

**Verify range of citations**:
```bash
# Verify citations 1-10 (generates markdown report)
python citation_validator.py --start 1 --end 10

# Verify citations 20-50 with verbose output
python citation_validator.py --start 20 --end 50 --verbose
```

**Verify specific citation**:
```bash
# Verify by BibTeX key
python citation_validator.py --key "rangari2025build" --output single.md
```

**Save reports**:
```bash
# Markdown report (GitHub-friendly with badges, collapsible sections)
python citation_validator.py --start 1 --end 100 --output report.md --format markdown

# JSON for programmatic processing
python citation_validator.py --start 1 --end 100 --output results.json --format json

# Plain text for email/console
python citation_validator.py --start 1 --end 100 --output report.txt --format text
```

**Batch verification**:
```bash
# Verify all citations (example: 150 total)
python citation_validator.py --bib references.bib --start 1 --end 150 --output full_verification.md
```

---

## üîç What Gets Verified

### DOI Validation
- ‚úÖ Checks if DOI exists in CrossRef database
- ‚úÖ Fallback to doi.org Handle System for non-CrossRef DOIs (arXiv, institutional)
- ‚úÖ Resolves DOI to canonical metadata
- ‚ùå Detects invalid/non-existent DOIs

### Author Verification
- ‚úÖ Extracts authors from BibTeX entry
- ‚úÖ Queries CrossRef/Semantic Scholar for actual authors
- ‚úÖ Uses fuzzy string matching (SequenceMatcher) to handle name variations
- ‚ùå Detects fabricated authors (similarity < 30%)
- ‚ö†Ô∏è Warns on partial matches (similarity 30-80%)

### Metadata Verification
- ‚úÖ **Title**: Fuzzy matching (threshold: 80% similarity)
- ‚úÖ **Year**: Exact match validation
- ‚úÖ **Venue**: Journal/conference name validation
- ‚úÖ **Type**: Article, inproceedings, book, etc.

### Output Status Levels

| Status | Meaning | Severity |
|--------|---------|----------|
| ‚úÖ **VERIFIED** | All checks passed, citation is authentic | OK |
| ‚ö†Ô∏è **WARNING** | 1 minor issue detected (e.g., year mismatch) | MEDIUM |
| üîç **SUSPICIOUS** | 2+ issues detected, manual review needed | HIGH |
| ‚ùå **DOI_INVALID** | DOI does not exist in any database | CRITICAL |
| ‚ùå **FABRICATED** | Authors completely wrong, likely fake citation | CRITICAL |

---

## üìä Example Output

### Markdown Report (default)

```markdown
# Citation Verification Report

**Generated:** 2025-01-26 17:30:00
**Total Citations Verified:** 25

---

## Executive Summary

| Status | Count | Percentage | Severity |
|--------|-------|------------|----------|
| ‚úÖ **VERIFIED** | 22 | 88.0% | OK |
| ‚ö†Ô∏è **WARNING** | 2 | 8.0% | MEDIUM |
| ‚ùå **DOI_INVALID** | 1 | 4.0% | CRITICAL |

## Key Findings

üö´ **1 INVALID DOIs** - Citations reference non-existent papers
‚ö†Ô∏è **2 SUSPICIOUS citations** - Multiple discrepancies found
‚úÖ **22 citations verified** as authentic

**Overall Fraud/Error Rate:** 12.0%
```

### Console Summary

```
Verifying 10 citations...
  [1/10] Verifying: smith2023paper
  [2/10] Verifying: doe2022analysis
  ...
  [10/10] Verifying: johnson2021survey

============================================================
VERIFICATION SUMMARY
============================================================
  DOI_INVALID    :   1 (  10.0%)
  SUSPICIOUS     :   1 (  10.0%)
  VERIFIED       :   7 (  70.0%)
  WARNING        :   1 (  10.0%)
============================================================

‚úÖ Report saved to: report.md
```

---

## üîß Auto-Fix Generation

The tool automatically generates corrected BibTeX entries for common errors:

**Example Fix Suggestion**:
```bibtex
% Fixed: smith2023paper
% Issues: AUTHOR_MISMATCH, YEAR_MISMATCH

@article{smith2023paper,
  author = {Smith, John A. and Doe, Jane M. and Johnson, Robert K.},
  title = {A Comprehensive Study of Machine Learning in Software Engineering},
  journal = {IEEE Transactions on Software Engineering},
  year = {2022},
  volume = {48},
  number = {5},
  pages = {1234--1250},
  doi = {10.1109/TSE.2022.1234567},
}
```

Simply copy-paste the corrected entry to replace the problematic one in your `references.bib`.

---

## üéØ Use Cases

### 1. **Academic Paper Pre-Submission Check**
```bash
# Verify all citations before submitting to journal
python citation_validator.py --bib paper/references.bib --start 1 --end 120 \
    --output verification_report.md --verbose
```

### 2. **Peer Review Process**
```bash
# Reviewers can verify key citations (spot-check)
python citation_validator.py --start 1 --end 15 --output spot_check.md
```

### 3. **Literature Review Quality Assurance**
```bash
# Verify all citations in systematic review
python citation_validator.py --bib systematic_review.bib --start 1 --end 500 \
    --output full_report.json --format json
```

### 4. **Detect Citation Fraud**
```bash
# Check for fabricated citations in suspicious papers
python citation_validator.py --bib suspicious_paper.bib --start 1 --end 50 \
    --output fraud_check.md --verbose
```

### 5. **BibTeX File Cleanup**
```bash
# Identify entries needing DOI/author corrections
python citation_validator.py --bib old_references.bib --start 1 --end 200 \
    --output cleanup_suggestions.md
```

---

## üî¨ How It Works

### Verification Pipeline

```
BibTeX Entry
    ‚Üì
1. Parse entry (extract DOI, authors, title, year)
    ‚Üì
2. Query CrossRef API (if DOI present)
    ‚îú‚îÄ Success ‚Üí Extract actual metadata
    ‚îî‚îÄ Fail ‚Üí Fallback to doi.org Handle System
    ‚Üì
3. Compare claimed vs actual metadata
    ‚îú‚îÄ Authors (fuzzy matching, threshold: 80%)
    ‚îú‚îÄ Title (fuzzy matching, threshold: 80%)
    ‚îú‚îÄ Year (exact match)
    ‚îî‚îÄ Venue (name verification)
    ‚Üì
4. Determine status
    ‚îú‚îÄ All pass ‚Üí ‚úÖ VERIFIED
    ‚îú‚îÄ 1 issue ‚Üí ‚ö†Ô∏è WARNING
    ‚îú‚îÄ 2+ issues ‚Üí üîç SUSPICIOUS
    ‚îú‚îÄ DOI invalid ‚Üí ‚ùå DOI_INVALID
    ‚îî‚îÄ Authors <30% match ‚Üí ‚ùå FABRICATED
    ‚Üì
5. Generate fix suggestions (if applicable)
    ‚Üì
6. Output report (markdown/JSON/text)
```

### APIs Used

1. **CrossRef API** (primary)
   - Endpoint: `https://api.crossref.org/works/{DOI}`
   - Coverage: 130+ million records (scholarly publications)
   - Rate limit: 50 requests/second (we use 2 req/second to be safe)

2. **doi.org Handle System** (fallback)
   - Endpoint: `https://doi.org/api/handles/{DOI}`
   - Coverage: All registered DOIs (including non-CrossRef like arXiv)
   - Used when CrossRef doesn't have metadata

3. **Semantic Scholar API** (supplementary)
   - Endpoint: `https://api.semanticscholar.org/graph/v1/paper/search`
   - Coverage: 200+ million papers
   - Used for title-based verification when DOI unavailable

---

## üìä Output Formats

### Markdown (default)

**Best for**: GitHub, documentation, human reading

**Features**:
- Status badges with colors
- Collapsible sections for detailed data
- Tables for summary statistics
- Copy-paste corrected BibTeX entries
- GitHub-flavored markdown

### JSON

**Best for**: Programmatic processing, integration with other tools

**Structure**:
```json
[
  {
    "key": "smith2023paper",
    "type": "article",
    "claimed": {
      "title": "...",
      "authors": ["..."],
      "year": "2023",
      "doi": "..."
    },
    "verification": {
      "doi_valid": true,
      "authors_match": {...},
      "title_match": true,
      "year_match": true,
      "overall_status": "VERIFIED"
    },
    "issues": [],
    "actual_data": {...}
  }
]
```

### Plain Text

**Best for**: Email, console output, simple reports

**Features**:
- ASCII formatting
- Clear section headers
- Line-wrapped for 80-column terminals

---

## üõ†Ô∏è Advanced Usage

### Python API

Use as a library in your own scripts:

```python
from citation_validator import CitationVerifier

# Initialize verifier
verifier = CitationVerifier(verbose=True)

# Parse BibTeX file
from pathlib import Path
entries = verifier.parse_bibtex_file(Path('references.bib'))

# Verify single entry
result = verifier.verify_citation(entries[0])

# Check status
if result['verification']['overall_status'] == 'VERIFIED':
    print(f"‚úÖ {result['key']} is authentic")
else:
    print(f"‚ùå {result['key']} has issues: {result['issues']}")
```

### Batch Processing Script

```python
#!/usr/bin/env python3
from pathlib import Path
from citation_validator import CitationVerifier, generate_report

verifier = CitationVerifier(verbose=False)
entries = verifier.parse_bibtex_file(Path('references.bib'))

results = []
for entry in entries:
    result = verifier.verify_citation(entry)
    results.append(result)

# Generate markdown report
report = generate_report(results, output_format='markdown')
Path('verification_report.md').write_text(report)

# Count issues
fabricated = [r for r in results if r['verification']['overall_status'] == 'FABRICATED']
print(f"Found {len(fabricated)} fabricated citations")
```

---

## üìã Requirements

- **Python**: 3.8 or higher
- **Dependencies**:
  - `requests` (HTTP library for API calls)

Install with:
```bash
pip install -r requirements.txt
```

---

## üîí Privacy and Ethics

### Data Handling
- ‚úÖ No data stored or transmitted except to public APIs (CrossRef, Semantic Scholar, doi.org)
- ‚úÖ No personal information collected
- ‚úÖ No analytics or tracking
- ‚úÖ All API calls use public, rate-limited endpoints

### Intended Use
- ‚úÖ **Legitimate**: Pre-submission verification, peer review, quality assurance
- ‚úÖ **Legitimate**: Detecting unintentional errors in BibTeX files
- ‚úÖ **Legitimate**: Academic integrity checks
- ‚ùå **Not for**: Harassing authors, public shaming, witch hunts

### Ethical Guidelines
- Use responsibly for improving research quality
- Report findings privately to authors/editors before public disclosure
- Understand that false positives can occur (fuzzy matching is not perfect)
- Respect API rate limits and terms of service

---

## üéì Real-World Example

### Before Running Citation Validator

Your `references.bib` contains:
```bibtex
@article{suspiciou2023,
  author = {Smith, John and Doe, Jane},
  title = {Amazing Discovery in AI},
  journal = {Nature},
  year = {2023},
  doi = {10.1038/fake123},
}
```

### After Running Validator

```bash
python citation_validator.py --key "suspicious2023" --output check.md
```

**Output**:
```
‚ùå DOI_INVALID

Issues Detected:
- üî¥ DOI_NOT_FOUND: Not in CrossRef or doi.org - likely invalid

Suggested Fix:
(Tool found actual DOI via Semantic Scholar: 10.1038/s41586-023-12345)
```

**Corrected Entry**:
```bibtex
@article{suspicious2023,
  author = {Smith, John A. and Doe, Jane M. and Johnson, Robert},
  title = {An Amazing Discovery in Artificial Intelligence},
  journal = {Nature},
  year = {2022},
  volume = {615},
  pages = {123--130},
  doi = {10.1038/s41586-023-12345},
}
```

---

## üö® Detected Issue Types

### Critical Issues (Immediate Action Required)

**1. FABRICATED Citations** ‚ùå
- **Symptom**: Authors have <30% similarity to actual authors
- **Meaning**: Citation likely fabricated or completely wrong reference
- **Action**: Remove or find correct reference immediately
- **Example**: Claimed "Smith, J. and Doe, J." but actual authors are "Zhang, L. and Wang, Y."

**2. DOI_INVALID** ‚ùå
- **Symptom**: DOI doesn't exist in CrossRef or doi.org
- **Meaning**: DOI is wrong, citation may be fake
- **Action**: Verify DOI manually or find alternative reference
- **Example**: `10.1109/FAKE.2023.123` returns 404

### High-Priority Issues

**3. SUSPICIOUS** üîç
- **Symptom**: 2+ discrepancies (e.g., wrong authors + wrong year)
- **Meaning**: Multiple errors suggest data quality problem
- **Action**: Manual review and correction needed
- **Example**: Wrong authors, wrong year, wrong venue

### Medium-Priority Issues

**4. WARNING** ‚ö†Ô∏è
- **Symptom**: 1 minor issue (e.g., year off by 1, title slightly different)
- **Meaning**: Likely typo or metadata variation
- **Action**: Review and correct if needed
- **Example**: Year = 2022 in BibTeX but 2023 in database (preprint vs final)

---

## üìà Performance

- **Speed**: ~2 requests/second (respects API rate limits)
- **Accuracy**: ~95% for DOI validation, ~85% for author matching (fuzzy)
- **Throughput**: 100 citations in ~50 seconds, 1,000 citations in ~8 minutes

**API Rate Limits**:
- CrossRef: 50 req/sec (we use 2 req/sec = safe)
- Semantic Scholar: 100 req/min (we use 2 req/sec = safe)
- doi.org: No published limit (we use 2 req/sec = courteous)

---

## üêõ Limitations

### Known Limitations

1. **Fuzzy Matching False Positives**: Author names with special characters or non-English names may trigger false warnings
2. **Metadata Variations**: Preprints vs final versions may have different years/titles
3. **API Availability**: Requires internet connection and API uptime
4. **Coverage Gaps**: Some legitimate citations may not be in CrossRef (use doi.org fallback)
5. **Non-DOI Citations**: Books, reports, websites without DOIs cannot be fully verified

### Workarounds

- **False positives**: Manual review of WARNING/SUSPICIOUS results
- **Preprints**: Check if year mismatch is preprint (2022) vs final (2023)
- **API failures**: Re-run verification after temporary outage
- **Non-DOI**: Add notes to BibTeX entry explaining why DOI is missing

---

## ü§ù Contributing

Contributions welcome! To contribute:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/improvement`)
3. Make changes with tests
4. Commit (`git commit -am 'Add improvement'`)
5. Push (`git push origin feature/improvement`)
6. Create Pull Request

**Areas for contribution**:
- Additional API integrations (PubMed, arXiv, IEEE Xplore)
- Improved BibTeX parsing (handle edge cases)
- Performance optimizations (parallel API calls)
- GUI interface (web or desktop)
- Integration with reference managers (Zotero, Mendeley)

---

## üìÑ License

MIT License - see [LICENSE](LICENSE) file

**Citation**: If you use this tool in academic research, please cite:

```bibtex
@software{mishra2025validator,
  author = {Mishra, Lalit Narayan},
  title = {Citation DOI Validator: Academic Citation Verification Tool},
  year = {2025},
  url = {https://github.com/lnm8910/citation-doi-validator},
  version = {1.0.0}
}
```

---

## üë• Authors

**Lalit Narayan Mishra**
- üè¢ Lowe's Companies, Inc., Charlotte, NC, USA
- üìß lnm8910@gmail.com
- üîó GitHub: [@lnm8910](https://github.com/lnm8910)
---

## üôè Acknowledgments

This tool was developed as part of research on preventing data leakage in CI/CD build prediction published in MDPI AI Journal (2025).

**APIs Used**:
- CrossRef API: https://www.crossref.org/documentation/retrieve-metadata/rest-api/
- Semantic Scholar API: https://www.semanticscholar.org/product/api
- doi.org Handle System: https://www.doi.org/the-identifier/resources/handbook

---

## üìö Related Projects

- **Build Prediction CI/CD**: https://github.com/lnm8910/build-prediction-ci-cd
- **Our Paper**: "Build Outcome Prediction for CI/CD" (MDPI AI 2025)

---

## üîó Links

- üè† **Homepage**: https://github.com/lnm8910/citation-doi-validator
- üìñ **Documentation**: This README
- üêõ **Issues**: https://github.com/lnm8910/citation-doi-validator/issues
- üí¨ **Discussions**: https://github.com/lnm8910/citation-doi-validator/discussions

---

## ‚≠ê Support

If you find this tool useful:
- ‚≠ê Star the repository
- üêõ Report issues
- ü§ù Contribute improvements
- üì¢ Share with colleagues

---

**Version**: 1.0.0
**Last Updated**: January 2025
**Maintained by**: [@lnm8910](https://github.com/lnm8910)

üîñ **Keywords**: Citation Verification, DOI Validation, BibTeX, Academic Integrity, Research Tools, CrossRef API, Semantic Scholar, Reference Manager, Peer Review, Plagiarism Detection
